wandb: Currently logged in as: shilin40 (better-diffusion-watermarks). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.15.12
wandb: Run data is saved locally in /nfshomes/shilin40/CMSC673/venv/tree-ring-watermark/wandb/run-20231104_230215-mae257zt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run no_attack
wandb: ‚≠êÔ∏è View project at https://wandb.ai/better-diffusion-watermarks/diffusion_watermark
wandb: üöÄ View run at https://wandb.ai/better-diffusion-watermarks/diffusion_watermark/runs/mae257zt
text_encoder/model.safetensors not found
Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]Loading pipeline components...:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:10<00:15,  5.10s/it]Loading pipeline components...:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:23<00:16,  8.49s/it]Loading pipeline components...:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:23<00:05,  5.42s/it]Loading pipeline components...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:26<00:00,  4.64s/it]Loading pipeline components...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:26<00:00,  5.38s/it]
/nfshomes/shilin40/CMSC673/venv/tree-ring-watermark/inverse_stable_diffusion.py:63: FutureWarning: Accessing config attribute `in_channels` directly via 'UNet2DConditionModel' object attribute is deprecated. Please access 'in_channels' over 'UNet2DConditionModel's config object instead, e.g. 'unet.config.in_channels'.
  num_channels_latents = self.unet.in_channels
  0%|          | 0/1000 [00:00<?, ?it/s]/nfshomes/shilin40/CMSC673/venv/lib/python3.11/site-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py:237: FutureWarning: `_encode_prompt()` is deprecated and it will be removed in a future version. Use `encode_prompt()` instead. Also, be aware that the output format changed from a concatenated tensor to a tuple.
  deprecate("_encode_prompt()", "1.0.0", deprecation_message, standard_warn=False)
/nfshomes/shilin40/CMSC673/venv/tree-ring-watermark/modified_stable_diffusion.py:140: FutureWarning: Accessing config attribute `in_channels` directly via 'UNet2DConditionModel' object attribute is deprecated. Please access 'in_channels' over 'UNet2DConditionModel's config object instead, e.g. 'unet.config.in_channels'.
  num_channels_latents = self.unet.in_channels

  0%|          | 0/50 [00:00<?, ?it/s][A
  2%|‚ñè         | 1/50 [00:08<07:11,  8.80s/it][A
  4%|‚ñç         | 2/50 [00:08<02:58,  3.72s/it][A
  6%|‚ñå         | 3/50 [00:09<01:38,  2.10s/it][A
  8%|‚ñä         | 4/50 [00:09<01:01,  1.34s/it][A
 10%|‚ñà         | 5/50 [00:09<00:41,  1.09it/s][A
 12%|‚ñà‚ñè        | 6/50 [00:09<00:29,  1.51it/s][A
 14%|‚ñà‚ñç        | 7/50 [00:09<00:21,  1.99it/s][A
 16%|‚ñà‚ñå        | 8/50 [00:09<00:16,  2.52it/s][A
 18%|‚ñà‚ñä        | 9/50 [00:10<00:13,  3.07it/s][A
 20%|‚ñà‚ñà        | 10/50 [00:10<00:11,  3.60it/s][A
 22%|‚ñà‚ñà‚ñè       | 11/50 [00:10<00:09,  4.07it/s][A
 24%|‚ñà‚ñà‚ñç       | 12/50 [00:10<00:08,  4.48it/s][A
 26%|‚ñà‚ñà‚ñå       | 13/50 [00:10<00:07,  4.82it/s][A
 28%|‚ñà‚ñà‚ñä       | 14/50 [00:11<00:07,  5.08it/s][A
 30%|‚ñà‚ñà‚ñà       | 15/50 [00:11<00:06,  5.28it/s][A
 32%|‚ñà‚ñà‚ñà‚ñè      | 16/50 [00:11<00:06,  5.43it/s][A
 34%|‚ñà‚ñà‚ñà‚ñç      | 17/50 [00:11<00:05,  5.54it/s][A
 36%|‚ñà‚ñà‚ñà‚ñå      | 18/50 [00:11<00:05,  5.62it/s][A
 38%|‚ñà‚ñà‚ñà‚ñä      | 19/50 [00:11<00:05,  5.68it/s][A
 40%|‚ñà‚ñà‚ñà‚ñà      | 20/50 [00:12<00:05,  5.71it/s][A
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 21/50 [00:12<00:05,  5.74it/s][A
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 22/50 [00:12<00:04,  5.77it/s][A
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/50 [00:12<00:04,  5.78it/s][A
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 24/50 [00:12<00:04,  5.77it/s][A
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 25/50 [00:12<00:04,  5.78it/s][A
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 26/50 [00:13<00:04,  5.78it/s][A
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 27/50 [00:13<00:03,  5.78it/s][A
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 28/50 [00:13<00:03,  5.78it/s][A
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 29/50 [00:13<00:03,  5.78it/s][A
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 30/50 [00:13<00:03,  5.78it/s][A
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 31/50 [00:13<00:03,  5.78it/s][A
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 32/50 [00:14<00:03,  5.78it/s][A
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 33/50 [00:14<00:02,  5.78it/s][A
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 34/50 [00:14<00:02,  5.78it/s][A
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 35/50 [00:14<00:02,  5.78it/s][A
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 36/50 [00:14<00:02,  5.78it/s][A
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 37/50 [00:14<00:02,  5.78it/s][A
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 38/50 [00:15<00:02,  5.78it/s][A
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 39/50 [00:15<00:01,  5.78it/s][A
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 40/50 [00:15<00:01,  5.78it/s][A
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 41/50 [00:15<00:01,  5.78it/s][A
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 42/50 [00:15<00:01,  5.78it/s][A
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 43/50 [00:16<00:01,  5.78it/s][A
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 44/50 [00:16<00:01,  5.77it/s][A
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 45/50 [00:16<00:00,  5.77it/s][A
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 46/50 [00:16<00:00,  5.77it/s][A
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 47/50 [00:16<00:00,  5.77it/s][A
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 48/50 [00:16<00:00,  5.77it/s][A
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 49/50 [00:17<00:00,  5.77it/s][A
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:17<00:00,  5.77it/s][A100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:17<00:00,  2.90it/s]
/nfshomes/shilin40/CMSC673/venv/lib/python3.11/site-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py:430: FutureWarning: The decode_latents method is deprecated and will be removed in 1.0.0. Please use VaeImageProcessor.postprocess(...) instead
  deprecate("decode_latents", "1.0.0", deprecation_message, standard_warn=False)
  0%|          | 0/1000 [00:18<?, ?it/s]
Traceback (most recent call last):
  File "/nfshomes/shilin40/CMSC673/venv/tree-ring-watermark/run_tree_ring_watermark.py", line 217, in <module>
    main(args)
  File "/nfshomes/shilin40/CMSC673/venv/tree-ring-watermark/run_tree_ring_watermark.py", line 65, in main
    outputs_no_w = pipe(
                   ^^^^^
  File "/nfshomes/shilin40/CMSC673/venv/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/nfshomes/shilin40/CMSC673/venv/tree-ring-watermark/modified_stable_diffusion.py", line 192, in __call__
    image = self.decode_latents(latents)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/nfshomes/shilin40/CMSC673/venv/lib/python3.11/site-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py", line 433, in decode_latents
    image = self.vae.decode(latents, return_dict=False)[0]
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/nfshomes/shilin40/CMSC673/venv/lib/python3.11/site-packages/diffusers/utils/accelerate_utils.py", line 46, in wrapper
    return method(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/nfshomes/shilin40/CMSC673/venv/lib/python3.11/site-packages/diffusers/models/autoencoder_kl.py", line 288, in decode
    decoded = self._decode(z).sample
              ^^^^^^^^^^^^^^^
  File "/nfshomes/shilin40/CMSC673/venv/lib/python3.11/site-packages/diffusers/models/autoencoder_kl.py", line 275, in _decode
    dec = self.decoder(z)
          ^^^^^^^^^^^^^^^
  File "/nfshomes/shilin40/CMSC673/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/nfshomes/shilin40/CMSC673/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/nfshomes/shilin40/CMSC673/venv/lib/python3.11/site-packages/diffusers/models/vae.py", line 272, in forward
    sample = up_block(sample, latent_embeds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/nfshomes/shilin40/CMSC673/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/nfshomes/shilin40/CMSC673/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/nfshomes/shilin40/CMSC673/venv/lib/python3.11/site-packages/diffusers/models/unet_2d_blocks.py", line 2375, in forward
    hidden_states = upsampler(hidden_states)
                    ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/nfshomes/shilin40/CMSC673/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/nfshomes/shilin40/CMSC673/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/nfshomes/shilin40/CMSC673/venv/lib/python3.11/site-packages/diffusers/models/resnet.py", line 170, in forward
    hidden_states = self.conv(hidden_states, scale)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/nfshomes/shilin40/CMSC673/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/nfshomes/shilin40/CMSC673/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/nfshomes/shilin40/CMSC673/venv/lib/python3.11/site-packages/diffusers/models/lora.py", line 163, in forward
    return F.conv2d(
           ^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 128.00 MiB. GPU 0 has a total capacty of 10.75 GiB of which 90.50 MiB is free. Including non-PyTorch memory, this process has 10.66 GiB memory in use. Of the allocated memory 10.21 GiB is allocated by PyTorch, and 261.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: - 0.006 MB of 0.006 MB uploaded (0.000 MB deduped)wandb: \ 0.006 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: | 0.015 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: üöÄ View run no_attack at: https://wandb.ai/better-diffusion-watermarks/diffusion_watermark/runs/mae257zt
wandb: Ô∏è‚ö° View job at https://wandb.ai/better-diffusion-watermarks/diffusion_watermark/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEwMzY3NDY2Ng==/version_details/v8
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231104_230215-mae257zt/logs
